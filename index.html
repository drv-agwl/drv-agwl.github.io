<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dhruv Agarwal</title>
  
  <meta name="author" content="Dhruv Agarwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dhruv Agarwal</name>
              </p>

              <p>I am currently a graduate student pursuing a Master's degree in Computer Science with a specialization in Artificial Intelligence at <strong><a href="https://ucsd.edu/">UC San Diego</a></strong>. Prior to my academic journey, I had the privilege of working as a Deep Learning Researcher at <a href="https://www.rephrase.ai/">Reprhase.ai</a>, where I was deeply immersed in cutting-edge AI technologies. At Reprhase.ai, I tackled a particularly challenging problem involving the generation of talking head videos from a single portrait image and an accompanying audio file. Additionally, I conceptualized and developed a proof of concept for a prosody correction deep learning model, which proved effective in rectifying prosody mismatches in audio files.</p>
              <p>Before my tenure at Reprhase.ai, I honed my skills as an Engineer at <a href="https://udaan.com">Udaan</a>, where I spent approximately 10 months focusing on AI solutions for robotic systems. My journey into the professional world began at <a href="https://www.sap.com/india/about/labs-india.html">SAP Labs India</a>, where I served as a Full-Stack Developer.</p>
              <p>My academic and research journey commenced with a rewarding internship with the <a href="https://www.inria.fr/en/stars">STARS team</a> at <a href="https://www.inria.fr/en/inria-centre-universite-cote-dazur">Inria, Sophia Antipolis</a>, where I collaborated with <a href="http://www-sop.inria.fr/members/Francois.Bremond/">Dr. Francois Bremond</a> for six months. During this period, my research interests centered on Multimodal Emotion and Personality Recognition. Additionally, I engaged in remote collaboration with <a href="https://ni.www.techfak.uni-bielefeld.de/people/anmelnik">Dr. Andrew Melnik</a> from the <a href="https://www.uni-bielefeld.de/">University of Bielefeld</a>, working on the development of neural networks to address complex physics challenges. Furthermore, I had the privilege of working with the <a href="https://www.maschinenbau.rwth-aachen.de/go/id/xom/lidx/1">WZL Lab, RWTH Aachen</a>, where I leveraged machine learning techniques to address measurement uncertainties in mechanical processes.</p>
              <p>I earned my Bachelor's degree in Information Technology from <strong><a href="https://www.iiita.ac.in/">IIIT Allahabad</a></strong>, where I had the invaluable opportunity to work under the mentorship of <a href="http://rkala.in/">Dr. Rahul Kala</a>. Our collaborative efforts focused on enhancing the localization accuracy of traditional SLAM (Simultaneous Localization and Mapping) algorithms through the application of deep learning techniques.</p>
              <p>For a more detailed overview of my qualifications, please refer to my  <a href="https://drive.google.com/file/d/1TDQw8Vj9qbLiZjrLT9KseZdANdZVCXtl/view?usp=sharing">Resume</a>.</p>
              <p style="text-align:center">
                <a href="mailto:drv.agwl@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/drv-agwl">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=pqnGBAsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/dhruv-ag/">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/dhruv.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/dhruv_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Interests</heading>
              <p>
In general, my interests lie in the realms of computer vision, machine learning, reinforcement learning, and physics. I am particularly fascinated by interdisciplinary research that allows me to leverage artificial intelligence in order to address complex challenges within the fields of robotics, healthcare, and medical science. My enthusiasm for exploring these domains is fueled by the potential to uncover innovative solutions that can positively impact the world and improve the human experience</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Industrial Projects</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="airavat_stop()" onmouseover="airavat_start()">
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <div class="one">
                <div class="two" id='airavat'><video  width=100% height=100% muted autoplay loop>
                <source src="images/airavat_trajectory.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/airavat.jpg' width="160">
              </div>
              <script type="text/javascript">
                function airavat_start() {
                  document.getElementById('airavat').style.opacity = "1";
                }
      
                function airavat_stop() {
                  document.getElementById('airavat').style.opacity = "0";
                }
                doom_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Single-shot Video Generation</papertitle>
            [<a href="https://github.com/drv-agwl/udaan-airavat">Code (private)</a>]
            <p>Airavat is an autonmous forklift which is capable of navigating itself and pick/put items in a warehouse. 
              It uses stereo camera (installed on the front of the bot) and other sensors for localizing itself in an environment. 
              Localization is also assisted by a map of April Tags placed strategically in the warehouse which help the bot to localize itself more robustly. 
              Moreover, the april tags also serve as the control points for a bezier curve which defines the trajectory of the robot.
            </p>
              
            <p> The video on the left (hover over the image on the left and zoom-in) of the description shows a simulation of Airavat following a pre-defined trajectory. 
            </p>
              
            </td>
          </tr>
          </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="airavat_stop()" onmouseover="airavat_start()">
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <div class="one">
              <div class="two" id='airavat'><video  width=100% height=100% muted autoplay loop>
              <source src="images/airavat_trajectory.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/airavat.jpg' width="160">
            </div>
            <script type="text/javascript">
              function airavat_start() {
                document.getElementById('airavat').style.opacity = "1";
              }
    
              function airavat_stop() {
                document.getElementById('airavat').style.opacity = "0";
              }
              doom_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Airavat</papertitle>
          [<a href="https://github.com/drv-agwl/udaan-airavat">Code (private)</a>]
          <p>Airavat is an autonmous forklift which is capable of navigating itself and pick/put items in a warehouse. 
            It uses stereo camera (installed on the front of the bot) and other sensors for localizing itself in an environment. 
            Localization is also assisted by a map of April Tags placed strategically in the warehouse which help the bot to localize itself more robustly. 
            Moreover, the april tags also serve as the control points for a bezier curve which defines the trajectory of the robot.
          </p>
            
          <p> The video on the left (hover over the image on the left and zoom-in) of the description shows a simulation of Airavat following a pre-defined trajectory. 
          </p>
            
          </td>
        </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Projects</heading>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/visapp_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>Multimodal Personality Recognition using Cross-Attention Transformer and Behaviour Encoding
              </papertitle>
              <br>
              <br>
              Tanay Agrawal, <strong>Dhruv Agarwal</strong>, Michal Balazia, Neelabh Sinha, Francois Bremond
              <br> 
              <em style="color: #c9314fde;">International Conference on Computer Vision Theory and Applications (VISAPP)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2112.12180">arXiv</a>

              <p>Personality recongnition using cross-attention transformers on multiple modalities and hand-crafted behaviour encodings.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/kd_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>From Multimodal to Unimodal Attention in Transformers using Knowledge
                Distillation</papertitle>
              <br>
              <br>
              <strong>Dhruv Agarwal</strong>, Tanay Agrawal, Laura M Ferrari, Francois Bremond
              <br> 
              <em style="color: #c9314fde;">Advanced Video and Signal-based Surveillance (AVSS)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2110.08270">arXiv</a>
        /
              <a href="https://docs.google.com/presentation/d/1rGbVZdNToWWN7Hu1tjELg6QmQOLFzbbnhH_Lj7hEy5o/edit?usp=sharing">Slides</a>
        
              <p>A new approach to applying knowledge distillation in transformers.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/nips_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>Solving Physics Puzzles by Reasoning about Paths</papertitle>
              <br>
              <br>
              Augustin Harter, Andrew Melnik, Gaurav Kumar, <strong>Dhruv Agarwal</strong>, Animesh Garg, Helge Ritter
              <br> 
              <em style="color: #c9314fde;">NeurIPS workshop on Interpretable Inductive Biases and Physically Structured Learning</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2011.07357">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=X30QGeIEXRs&t=5s">Video</a>
        /
              <a href="https://github.com/ndrwmlnk/PHYRE-Reasoning-about-Paths">Code</a>

              <p>A new deep learning model for goal-driven tasks that require intuitive
                physical reasoning and intervention in the scene to achieve a desired end goal.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/slam_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle>SLAM and Map Learning using Hybrid Semantic Graph Optimization</papertitle>
              <br>
              <br>
              Ambuj Agrawal, <strong>Dhruv Agarwal</strong>, Mehul Arora, Ritik Mahajan, Shivansh Beohar, Lhilo Kenye, Rahul Kala. (<strong> equal contribution </strong>)
              <br> 
              <em style="color: #c9314fde;">Mediterranean Conference on Control and Automation, 2022</em>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9837164">Paper</a>
        
              <p>Improved localization accuracy of V-SLAM by injecting semantic information of detected corner
                points from images captured by a robot. Detected object in a scene were used for place recognition and correspondence matching which further
                enhanced the semantic information provided to V-SLAM module.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/images/measurement_migration_paper.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <papertitle> Similarity assessment and model migration for measurement processes </papertitle>.
              <br>
              <br>
              <strong>Dhruv Agarwal</strong>, Meike Huber, Robert Schmitt.
              <br> 
              <em style="color: #c9314fde;">International Journal of Quality & Reliability Management (IJQRM), 2022</em>
              <br>
              <a href="https://drive.google.com/file/d/1CvJXGRnnLykAp5VzoiUAZtq44Iq8HbST/view?usp=sharing">Paper</a>
        
              <p>The determination of the measurement uncertainty is relevant for all measurement processes. In production engineering, the measurement uncertainty needs to be known to avoid erroneous decisions. However, its determination is associated to high effort due to the expertise and expenditure that is needed for modelling measurement processes. Once a measurement model is developed, it cannot necessarily be used for any other measurement process. In order to make an existing model usable for other measurement processes and thus to reduce the effort for the determination of the measurement uncertainty, a procedure for the migration of measurement models has to be developed.</p>
            </td>
          </tr>
          
        </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Independent Projects</heading>
      </tbody></table>
          
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/IGR.png" alt="project image" style="width:auto; height:auto; max-width:100%; max-height:120%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Unofficial Implementation of Implicit Neural Representation with Phase Loss and Fourier Features
            </papertitle>
          [<a href="https://github.com/drv-agwl/Implicit_Neural_Representation">Code</a>]
          <p>The project contains an unofficial implementation of the Phase Transitions, Distance Functions, and Implicit Neural Representations 
            <a href="https://arxiv.org/pdf/2106.07689.pdf">paper</a>. The paper proposes a new loss function, phase loss, which improves the 3D reconstruction performance for Implicit Neural Representation. The project implements the phase loss proposed in the paper and an optional fourier layer in the network which further enhances the performance for high frequency signals</p>
          </td>
        </tr>

        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/vivit_project.png" alt="project image" style="width:auto; height:auto; max-width:100%; max-height:120%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Unofficial Implementation of ViViT</papertitle>
          [<a href="https://github.com/drv-agwl/ViViT-pytorch">Code</a>]
          <p>The project contains an unofficial implementation of the Video Vision Transformer (ViViT) 
            <a href="https://arxiv.org/abs/2103.15691">paper</a>. Owing to the recent success of transformers in image classification task, 
            the paper presents a pure transformer architecture which can be exploited for video classification or for 
            extracting rich features from videos.</p>
          </td>
        </tr>  
        
        <tr onmouseout="doom_stop()" onmouseover="doom_start()">
          <!-- <td style="padding:20px;width:25%;vertical-align:middle"> -->
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <div class="one">
              <div class="two" id='doom'><video  width=100% height=100% muted autoplay loop>
              <source src="images/doom.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/doom.jpg' width="160">
            </div>
            <script type="text/javascript">
              function doom_start() {
                document.getElementById('doom').style.opacity = "1";
              }
    
              function doom_stop() {
                document.getElementById('doom').style.opacity = "0";
              }
              doom_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Deep Reinforcement Learning on Games</papertitle>
          [<a href="https://github.com/drv-agwl/Reinforcement-Learning">Code</a>]
          <p>Implementation various state-of-the-art reinforcement learning algorithms to make an AI agent learn to play
            Doom, Space Invaders, Sonic Hedgehog 2, etc.</p>
          </td>
        </tr>

        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/face-gen_project.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Face Generation</papertitle>
          [<a href="https://github.com/drv-agwl/Face-Generation-Using-DCGANs">Code</a>]
          <p>A repertoire of Deconvolutional GAN models trained to output artificial human face images. The models were trained on the <a href="https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a> dataset</p>
          </td>
        </tr> 

        <tr>
          <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
            <img src="/images/art-gen.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
          </td>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <papertitle>Art Maker</papertitle>
          [<a href="https://github.com/drv-agwl/Neural-Style-Transfer">Code</a>]
          <p> A VGG model trained using Neural Style Transfer technique to generate artisitic images from a base image and a style image.</p>
          </td>
        </tr> 

      </tbody></table>

      <br>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;display:block;">
        <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>Blogs</heading>
            <br>
            <br>
          </td>
        </tr>

        <tr style="width: 100%; display: block;">
          <td style="padding:1%;width:25%;vertical-align:middle">
            <a  href="https://dev.to/hintiiita/getting-prepped-with-machine-learning-skills-for-a-hackathon-2nhm">
              <img src="/images/blog.png" alt="project image" style="display: block; width:auto; height:auto; max-width:50%; margin:0 auto;" >
            </a>
          </td>
        </tr>
      </table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:center;font-size:small;">
              Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
            </p>
          </td>
        </tr>
      </tbody></table>

    </td>
    </tr>
  </table>
</body>

</html>
